{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "L,d_k,d_v=4,8,8\n",
    "q=np.random.randn(L,d_k)\n",
    "k=np.random.randn(L,d_k)\n",
    "v=np.random.randn(L,d_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[-0.70944123 -0.01773769  0.00660004  0.03448526  0.22175656  2.26415323\n",
      "   1.93139     3.06905117]\n",
      " [ 0.38648036  0.8095378  -0.39726029  1.16352854 -1.56546819  0.11917732\n",
      "   0.85248551 -1.98310562]\n",
      " [-0.92242717 -2.38675021 -1.28550749 -1.4020073  -1.33840008 -0.16222289\n",
      "  -0.66943553 -1.00281251]\n",
      " [-0.03767562  0.26171853  0.44964634 -0.50946774 -0.69681987  0.60648336\n",
      "   0.41978713 -0.22402015]]\n",
      "K\n",
      " [[-0.15465855 -0.21578203 -0.77629568  0.35883392 -0.8689555  -0.78750826\n",
      "   2.66052276  0.72965596]\n",
      " [ 0.47434482  1.84712089 -0.78525318  1.33067049 -1.31327505 -0.19759242\n",
      "   0.04891668  0.96763674]\n",
      " [ 2.0372846   0.41433253 -0.34158634  1.39513177 -1.18161527 -1.85961313\n",
      "  -0.38594565 -1.52652472]\n",
      " [ 1.25096607  0.2844642   0.06900961 -0.78687934  0.18154905 -0.52867144\n",
      "   0.98693017 -0.96660375]]\n",
      "V\n",
      " [[-1.25252297  0.14268162  0.91559593 -0.02155435  0.37997314 -0.59708641\n",
      "  -1.3296059   2.03094207]\n",
      " [ 0.80542341  0.26978001 -1.58675757 -0.59494545  0.80059199 -0.69455677\n",
      "  -0.92825924  0.07827129]\n",
      " [ 0.26320126  0.54746877  1.90418576 -0.10166761 -0.95410443  0.12217695\n",
      "   0.49736616  0.91892156]\n",
      " [ 2.00343376  2.12384392 -0.2517703   0.06544683 -0.65388383  0.38168219\n",
      "  -0.39704139  1.16117302]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Q\\n\",q)\n",
    "print(\"K\\n\",k)\n",
    "print(\"V\\n\",v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mulitply the query vector to the transpose of the of K vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.52292208,   1.99701933, -11.30970006,  -3.13635568],\n",
       "       [  2.57899011,   3.69397881,   7.20816671,   2.1817931 ],\n",
       "       [ -0.06946941,  -4.91568898,  -0.71269844,  -0.66695832],\n",
       "       [  0.49877028,   0.03357874,  -0.95717927,   0.64294007]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(q,k.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following 4*4 matrix tells how a particular word is related to the other word. In the first row the after the word's affinity with itself it has greatest affinity to the second word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3465203815980025, 1.1421827853397775, 17.220820204786598)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var(),k.var(),np.matmul(q,k.T).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As evident in the above values of variance q vector & k vector's variance is close to 1, however the variance of q*K.T vector is high. To reduce the variance self attention formula has the division of the product with sqrt(d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3465203815980025, 1.1421827853397775, 2.152602525598324)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled=(np.matmul(q,k.T)/math.sqrt(d_k))\n",
    "q.var(),k.var(),scaled.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=np.tril(np.ones((L,L)))\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following mask function will generate a triangular matrix. \n",
    "The 1's in the matrix ensure that the context is relevant to nearest words and not the succeeding ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[mask==0]=float(\"-inf\")\n",
    "mask[mask==1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.95264783,        -inf,        -inf,        -inf],\n",
       "       [ 0.9118107 ,  1.30601873,        -inf,        -inf],\n",
       "       [-0.02456115, -1.73795851, -0.25197695,        -inf],\n",
       "       [ 0.17634192,  0.01187188, -0.33841398,  0.22731364]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled + mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.04732298, 0.        , 0.        , 0.        ],\n",
       "       [2.48882496, 3.69144777, 0.        , 0.        ],\n",
       "       [0.97573802, 0.17587909, 0.77726265, 0.        ],\n",
       "       [1.19284585, 1.01194263, 0.7129001 , 1.2552235 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(scaled+mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.329387571474136"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.exp(scaled+mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.04732298, 6.18027274, 1.92887977, 4.17291208])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.exp(scaled+mask),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.40270471, 0.59729529, 0.        , 0.        ],\n",
       "       [0.50585736, 0.09118199, 0.40296065, 0.        ],\n",
       "       [0.28585454, 0.24250274, 0.17083995, 0.30080277]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.exp(scaled+mask).T/np.sum(np.exp(scaled+mask),axis=1)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax function is used to convert the sclaed matrix into a probablitiy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.40270471, 0.59729529, 0.        , 0.        ],\n",
       "       [0.50585736, 0.09118199, 0.40296065, 0.        ],\n",
       "       [0.28585454, 0.24250274, 0.17083995, 0.30080277]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return (np.exp(x).T/np.sum(np.exp(x),axis=-1)).T\n",
    "def scaled_dot_product_attention(q,k,v,mask=None):\n",
    "    d_k=k.shape[1]\n",
    "    scaled=np.matmul(q,k.T)/math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled=scaled+mask\n",
    "    attention=softmax(scaled)\n",
    "    out=np.matmul(attention,v)\n",
    "    return out.attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
